{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from scipy.special import expit\n",
    "from time import sleep\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove warning generated by classifier libraries.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MyConfusionMatrix(Y,ClassNames):\n",
    "    print(confusion_matrix(ClassNames, Y))\n",
    "    return confusion_matrix(ClassNames, Y),accuracy_score(ClassNames, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============================ Predicts probability of labels for RVM ==============================================='''\n",
    "def predict_proba(clf,XValidate):\n",
    "    noOfClasses = np.shape(clf.classes_)[0]\n",
    "    noOfClassifiers = (noOfClasses * (noOfClasses-1))/2\n",
    "    print('no of Classifiers',noOfClassifiers)\n",
    "    dataSize = np.shape(XValidate)[0]\n",
    "    Yvalidate = np.zeros((dataSize, np.shape(clf.classes_)[0]))\n",
    "    c = 0\n",
    "    prob = clf.multi_.estimators_[c].predict_proba(XValidate)\n",
    "    #Summing Fkm(X) where k!=m\n",
    "    for i in range(0,noOfClasses):\n",
    "        for j in range(i, noOfClasses):\n",
    "            if (i < j):\n",
    "                Yvalidate[:, i] =  Yvalidate[:, i]+ prob[:, 0]\n",
    "                Yvalidate[:, j] =  Yvalidate[:, j]+ prob[:, 1]\n",
    "                c = c + 1;\n",
    "                if(c<noOfClassifiers):\n",
    "                    prob = clf.multi_.estimators_[c].predict_proba(XValidate)\n",
    "    #Calculating 1/G(summation(ykm))\n",
    "    Yvalidate = Yvalidate / np.shape(clf.classes_)[0]\n",
    "    #Calculating probability of XValidate  not belonging to any class\n",
    "    prob_std = np.ndarray.std(Yvalidate, axis=1)[:, np.newaxis]\n",
    "    sigmoid = 1 - expit(prob_std)\n",
    "    Yvalidate = np.concatenate([Yvalidate, sigmoid], axis=1)\n",
    "    Yvalidate = Yvalidate / np.repeat((sigmoid + 1), axis=1, repeats=np.shape(clf.classes_)[0] + 1)\n",
    "    return Yvalidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''====================== Method to get the Parameters and the HyperParameters ====================================='''\n",
    "def get_params(clf):\n",
    "    if np.shape(clf.classes_)[0] == 2:\n",
    "        Parameters = [{'phi': clf.phi,'relevance': clf.relevance_,'alpha': clf.alpha_,'beta': clf.beta_,'m': clf.m_,\n",
    "                       'gamma': clf.gamma,'bias': clf.bias,'clf': clf}]\n",
    "    else :\n",
    "        Parameters = [clf]\n",
    "        for c in clf.multi_.estimators_:\n",
    "            Parameter = {'phi': c.phi,'relevance': c.relevance_,'alpha': c.alpha_,'beta': c.beta_,'m': c.m_,\n",
    "                         'gamma': c.gamma,'bias': c.bias,'clf': c}\n",
    "            Parameters.append(Parameter)\n",
    "    return Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_svc(parameters):\n",
    "    svc = SVC(C=parameters['parameters']['C'], kernel=parameters['parameters']['kernel'],\n",
    "              degree=parameters['parameters']['degree'], gamma=parameters['parameters']['gamma'],\n",
    "              coef0=parameters['parameters']['coef0'], probability=parameters['parameters']['probability'],\n",
    "              tol=parameters['parameters']['tol'], cache_size=parameters['parameters']['cache_size'],\n",
    "              class_weight=parameters['parameters']['class_weight'], shrinking=parameters['parameters']['shrinking'],\n",
    "              verbose=parameters['parameters']['verbose'], max_iter=parameters['parameters']['max_iter'],\n",
    "              decision_function_shape=parameters['parameters']['decision_function_shape'],\n",
    "              random_state=parameters['parameters']['random_state'])\n",
    "    return svc\n",
    "\n",
    "\n",
    "def svc_train(svc, estimate, labels):\n",
    "    svc.fit(estimate, labels)\n",
    "\n",
    "\n",
    "def svc_predict(svc, validate):\n",
    "    return svc.predict(validate)\n",
    "\n",
    "\n",
    "def svc_probability(svc, validate):\n",
    "    return svc.predict_proba(validate)\n",
    "\n",
    "\n",
    "def svc_score(svc, validate, v_labels):\n",
    "    return svc.score(validate, v_labels)\n",
    "\n",
    "\n",
    "def svc_get_para(svc):\n",
    "    support = svc.support_\n",
    "    support_vectors = svc.support_vectors_\n",
    "    n_support = svc.n_support_\n",
    "    dual_coef = svc.dual_coef_\n",
    "    intercept = svc.intercept_\n",
    "    sparse = svc._sparse\n",
    "    shape_fit = svc.shape_fit_\n",
    "    prob_a = svc.probA_\n",
    "    prob_b = svc.probB_\n",
    "    gamma = svc._gamma\n",
    "    classes = svc.classes_\n",
    "    hyper = svc.get_params(deep=True)\n",
    "    ret = {'support': support, 'support_vectors': support_vectors, 'n_support': n_support, 'dual_coef': dual_coef,\n",
    "           'intercept': intercept, 'sparse': sparse, 'shape_fit': shape_fit, 'prob_a': prob_a, 'prob_b': prob_b,\n",
    "           'gamma': gamma, 'classes': classes, 'hyper': hyper}\n",
    "    return ret\n",
    "\n",
    "\n",
    "def svc_set_para(svc, svc_para):\n",
    "    svc.set_params(**svc_para['hyper'])\n",
    "    svc.support_ = svc_para['support']\n",
    "    svc.support_vectors_ = svc_para['support_vectors']\n",
    "    svc.n_support_ = svc_para['n_support']\n",
    "    svc._dual_coef_ = svc_para['dual_coef']\n",
    "    svc._intercept_ = svc_para['intercept']\n",
    "    svc._sparse = svc_para['sparse']\n",
    "    svc.shape_fit_ = svc_para['shape_fit']\n",
    "    svc.probA_ = svc_para['prob_a']\n",
    "    svc.probB_ = svc_para['prob_b']\n",
    "    svc._gamma = svc_para['gamma']\n",
    "    svc.classes_ = svc_para['classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper funtions for MyCrossValidate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVhelper(args):\n",
    "    XEstimate=args[0]\n",
    "    XValidate= args[1]\n",
    "    YEstimate=args[2]\n",
    "    YValidateTrue=args[3]\n",
    "    algo=args[4]\n",
    "    params=args[5]\n",
    "                \n",
    "    # calling TrainMyClassifier\n",
    "    YValidate, Estparameters = TrainMyClassifier(XEstimate, YEstimate, XValidate,\n",
    "                                                 {'algorithm':algo, 'parameters':params })\n",
    "                \n",
    "                \n",
    "    score = (YValidateTrue == np.sum(np.argmax(YValidate, axis=1))/np.size(YValidateTrue))*100\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TrainMyClassifier(XEstimate, ClassLabels, XValidate, Parameters ):\n",
    "    if Parameters['algorithm'] == 'RVM':\n",
    "        Parameters = Parameters['parameters']\n",
    "        clf =  RVC(alpha=Parameters.get('alpha'),beta=Parameters.get('beta'),n_iter=Parameters.get('n_iter'))\n",
    "        clf.fit(XEstimate, ClassLabels)\n",
    "        if np.shape(clf.classes_)[0] == 2:\n",
    "            Yvalidate = clf.predict_proba(XValidate)\n",
    "        else:\n",
    "            Yvalidate = predict_proba(clf,XValidate)\n",
    "        EstParameters = get_params(clf)\n",
    "        return Yvalidate,EstParameters\n",
    "\n",
    "    elif Parameters['algorithm'] == 'SVM':\n",
    "        \n",
    "        svc = get_svc(Parameters)\n",
    "        svc_train(svc, XEstimate, ClassLabels)\n",
    "        prob = svc_probability(svc, XValidate)\n",
    "        EstParameters = svc_get_para(svc)\n",
    "        \n",
    "        prob_std = np.ndarray.std(prob, axis=1)[:, np.newaxis]\n",
    "        sigmoid = 1 - expit(prob_std)\n",
    "        Yvalidate = np.concatenate([prob, sigmoid], axis=1)\n",
    "        Yvalidate = Yvalidate / np.repeat((sigmoid + 1), axis=1, repeats=len(svc.classes_)+1)\n",
    "        \n",
    "        return Yvalidate, EstParameters\n",
    "\n",
    "    elif Parameters[\"algorithm\"] == \"GPR\":\n",
    "        # get the classes from the labels\n",
    "        classes = np.unique(ClassLabels, axis=0)\n",
    "        sorted(classes, reverse=True)\n",
    "        num_class = len(classes)\n",
    "\n",
    "        # get data and label based on classes\n",
    "        data = []\n",
    "        for cla in classes:\n",
    "            data.append(XEstimate[ClassLabels == cla])\n",
    "\n",
    "        target = []\n",
    "        for cla in classes:\n",
    "            target.append(ClassLabels[ClassLabels == cla])\n",
    "\n",
    "        # put data and label into a matrix, so that we could do a easier calculation for probability\n",
    "        # the following calculation is all based on the matrix\n",
    "        data_matrix = []\n",
    "        for i in range(num_class - 1):\n",
    "            data_matrix.append([])\n",
    "            for j in range(num_class - 1):\n",
    "                data_matrix[i].append(None)\n",
    "\n",
    "        target_matrix = []\n",
    "        for i in range(num_class - 1):\n",
    "            target_matrix.append([])\n",
    "            for j in range(num_class - 1):\n",
    "                target_matrix[i].append(None)\n",
    "\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                data_matrix[i][j] = np.concatenate([data[i], data[j+1]], axis=0)\n",
    "                target_matrix[i][j] = np.concatenate([target[i], target[j+1]], axis=0)\n",
    "\n",
    "        classifier_matrix = []\n",
    "        for i in range(num_class-1):\n",
    "            classifier_matrix.append([])\n",
    "            for j in range(num_class-1):\n",
    "                classifier_matrix[i].append(None)\n",
    "\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                gpc_classifier = GaussianProcessClassifier(\n",
    "                    kernel=Parameters[\"parameters\"][\"kernel\"],\n",
    "                    optimizer=Parameters[\"parameters\"][\"optimizer\"],\n",
    "                    n_restarts_optimizer=Parameters[\"parameters\"][\"n_restarts_optimizer\"],\n",
    "                    max_iter_predict=Parameters[\"parameters\"][\"max_iter_predict\"],\n",
    "                    warm_start=Parameters[\"parameters\"][\"warm_start\"],\n",
    "                    copy_X_train=Parameters[\"parameters\"][\"copy_X_train\"],\n",
    "                    random_state=Parameters[\"parameters\"][\"random_state\"],\n",
    "                    multi_class=\"one_vs_rest\",\n",
    "                    n_jobs=Parameters[\"parameters\"][\"n_jobs\"]\n",
    "                )\n",
    "                gpc_classifier.fit(data_matrix[i][j], target_matrix[i][j])\n",
    "                classifier_matrix[i][j] = gpc_classifier\n",
    "\n",
    "        out_matrix = []\n",
    "        for i in range(num_class-1):\n",
    "            out_matrix.append([])\n",
    "            for j in range(num_class-1):\n",
    "                out_matrix[i].append(None)\n",
    "\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                out_matrix[i][j] = classifier_matrix[i][j].predict_proba(XValidate)\n",
    "\n",
    "        # calculate the whole prediction prob\n",
    "        val_shape = XValidate.shape[0]\n",
    "        predict_prob_list = []\n",
    "        for i in range(num_class):\n",
    "            predict_prob_list.append(np.zeros(shape=[val_shape, 1]))\n",
    "\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                predict_prob_list[i] += out_matrix[i][j][:, 0][:, np.newaxis] / (num_class * 2)\n",
    "                predict_prob_list[j + 1] += out_matrix[i][j][:, 1][:, np.newaxis] / (num_class * 2)\n",
    "\n",
    "        # get the result of num_class probability\n",
    "        result = np.concatenate(predict_prob_list, axis=1)\n",
    "\n",
    "        # calculate the probability for the one more class\n",
    "        std = np.std(result, axis=1)[:, np.newaxis]\n",
    "        other_prob = np.exp(-std) / (1 + np.exp(std * 5))\n",
    "        result = np.concatenate([result, other_prob], axis=1)\n",
    "        result = result / np.repeat((other_prob + 1), axis=1, repeats=num_class + 1)\n",
    "\n",
    "        # put all the parameters into a dict\n",
    "        estParameters = {}\n",
    "        estParameters[\"class_num\"] = num_class\n",
    "        estParameters[\"parameters\"] = []\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                estParameters[\"parameters\"].append(\n",
    "                    {\n",
    "                        \"log_marginal_likelihood_value_\": classifier_matrix[i][j].log_marginal_likelihood_value_,\n",
    "                        \"classes_\": classifier_matrix[i][j].classes_,\n",
    "                        \"n_classes_\": classifier_matrix[i][j].n_classes_,\n",
    "                        \"base_estimator_\": classifier_matrix[i][j].base_estimator_\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        return result, estParameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MyCrossValidate(XTrain, ClassLabels, Nf):\n",
    "    \"\"\"\n",
    "    Xtrain: Training data with labels\n",
    "    ClassLabels: Class labels for train set.\n",
    "    Nf: Number of folds\n",
    "    \n",
    "    returns:\n",
    "            Array of Ytrain:\n",
    "            Array of EstParameters:\n",
    "            Array of EstConfMatrices:\n",
    "            Array of ConfMatrix:\n",
    "    \"\"\"\n",
    "    \n",
    "    algorithms = ['RVM']\n",
    "    parameters = {'SVM':{'C' : [1, 5, 10], 'kernel' : ['rbf','poly'], 'degree' : [2, 3, 5], 'gamma' : ['auto'],\n",
    "                            'coef0' : [0.0], 'probability' : [True], 'shrinking' : [True], 'tol' : [1e-3, 1e-4],\n",
    "                            'class_weight' : ['balanced'], 'verbose' : [False], 'max_iter' : [-1],\n",
    "                            'decision_function_shape' : ['ovo'], 'random_state' : [None], 'cache_size': [800]},\n",
    "                  \n",
    "                 'RVM':{ 'kernel':['rbf'],'degree':[3],'coef1':[None],'coef0':[0.0],'n_iter':[500],'tol':[1e-3],\n",
    "                        'alpha':[100,1,1e-6],'threshold_alpha':[1e9],'beta':[1.e-2 ,1.e-6, 1.e-8],'beta_fixed':[False],\n",
    "                        'bias_used':[True],'verbose':[False]},\n",
    "                  \n",
    "                 'GPR':{\"kernel\": [ 1.0 * RBF(1), \n",
    "                                    2.0 * RBF(1),\n",
    "                                    3.0 * RBF(1),\n",
    "                                    1.0 * RBF(2),\n",
    "                                    1.0 * RBF(3)\n",
    "                                    ],\n",
    "                              \"optimizer\": [\"fmin_l_bfgs_b\"],\n",
    "                              \"n_restarts_optimizer\": [0],\n",
    "                              \"max_iter_predict\": [100],\n",
    "                              \"warm_start\": [True],\n",
    "                              \"copy_X_train\": [True],\n",
    "                              \"random_state\": [0],\n",
    "                              \"multi_class\": [\"one_vs_one\"],\n",
    "                              \"n_jobs\": [-1]}}\n",
    "    \n",
    "    # de code ClassLabels to numbers \n",
    "    ClassLabels = np.argmax(ClassLabels, axis=1)\n",
    "    \n",
    "    \n",
    "    algo_score = []\n",
    "    algo_params = []\n",
    "    \n",
    "    Ytrain = []\n",
    "    EstParameter = []\n",
    "    EstConfMatrices = []\n",
    "    ConfMatrix = []\n",
    "    for algo in algorithms:\n",
    "        \n",
    "        # generating hyper parameter array for hyper parameter search.\n",
    "        grid = ParameterGrid(parameters[algo])\n",
    "        grid_search_score = []\n",
    "        pbar = tqdm(list(grid))\n",
    "        for params in pbar:\n",
    "            pbar.set_description(\"Searching Parameters for {}\".format(algo))\n",
    "            # scikit-learn object to divide data set in Estimate and Validate sets.\n",
    "            k_fold = KFold(n_splits=Nf, random_state=None, shuffle=False)\n",
    "            \n",
    "            # Array of scores for each split.\n",
    "            cv_scores = []\n",
    "            p = Pool(5)\n",
    "            p_params =[]\n",
    "            for train_index, val_index in k_fold.split(XTrain):\n",
    "\n",
    "                # Spliting data in Estimate and validate set.\n",
    "                XEstimate, XValidate = XTrain[train_index], XTrain[val_index]\n",
    "                YEstimate, YValidateTrue = ClassLabels[train_index], ClassLabels[val_index]\n",
    "                p_params.append([XEstimate, XValidate, YEstimate, YValidateTrue, algo, params])\n",
    "            \n",
    "            cv_scores = p.map(CVhelper, p_params)\n",
    "            \n",
    "            # average accuracy for selected hyper parameters \n",
    "            score = np.mean(cv_scores)\n",
    "            grid_search_score.append(score)\n",
    "\n",
    "        # calculating best hyper parameters\n",
    "        idx = np.argmax(grid_search_score)\n",
    "        best_params = list(grid)[idx]\n",
    "        \n",
    "        # storing best algorithm score and hyper parameters\n",
    "        algo_score.append(np.max(grid_search_score))\n",
    "        algo_params.append(best_params)\n",
    "        \n",
    "        \n",
    "        # calculating method out for current algorithm\n",
    "        _Ytrain = []\n",
    "        _EstParameter = []\n",
    "        _EstConfMatrices = []\n",
    "        _ConfMatrix = []\n",
    "\n",
    "        # scikit-learn object to divide data set in Estimate and Validate sets.\n",
    "        k_fold = KFold(n_splits=Nf, random_state=None, shuffle=False)\n",
    "\n",
    "        _all_Yval_true = []\n",
    "        _all_Yval_pred = []\n",
    "        index = 0\n",
    "        \n",
    "        print(\"Average cross validation score for {} is {}%.\".format(algo, np.max(grid_search_score)))\n",
    "        for train_index, val_index in k_fold.split(XTrain):\n",
    "\n",
    "            # Spliting data in Estimate and validate set.\n",
    "            XEstimate, XValidate = XTrain[train_index], XTrain[val_index]\n",
    "            YEstimate, YValidateTrue = ClassLabels[train_index], ClassLabels[val_index]\n",
    "\n",
    "            # calling TrainMyClassifier\n",
    "            YValidate, Estparameters = TrainMyClassifier(XEstimate, YEstimate, XValidate,\n",
    "                                                         {'algorithm':algo, 'parameters':best_params })\n",
    "            \n",
    "            # storing TrainMyClassifier's output  \n",
    "            _Ytrain.append(YValidate)\n",
    "            _EstParameter.append(Estparameters)\n",
    "            \n",
    "            # printing kernel numbers \n",
    "            if  algo == 'SVM':\n",
    "                print('Number of support vector for validation set {}: {}'.format(index, len(Estparameters['support_vectors'])))\n",
    "            elif  algo == 'RVM':\n",
    "                print('Number of relavance vector for validation set {}: {}'.format(index, len(Estparameters['relevant_vectors'])))\n",
    "                \n",
    "            # calculating confusion matrix for validation set\n",
    "            print(\"Confusion matrix for validation set {}: \".format(index))\n",
    "            _EstConfMatrices.append(MyConfusionMatrix(np.argmax(YValidate, axis=1), YValidateTrue))\n",
    "            \n",
    "            \n",
    "            _all_Yval_true.extend(YValidateTrue.tolist())\n",
    "            _all_Yval_pred.extend(np.argmax(YValidate, axis=1).tolist())\n",
    "            \n",
    "            index+=1\n",
    "        print(\"Over all Confusion matrix for {}: \".format(algo))\n",
    "        # calculating over all confusion matrix for validation set\n",
    "        _all_Yval_pred = np.array(_all_Yval_pred).reshape(len(_all_Yval_pred),1)\n",
    "        _all_Yval_true = np.array(_all_Yval_true).reshape(len(_all_Yval_true),1)\n",
    "        _ConfMatrix = MyConfusionMatrix(_all_Yval_pred, _all_Yval_true)\n",
    "        \n",
    "        # append Main outputs\n",
    "        Ytrain.append(_Ytrain)\n",
    "        EstParameter.append(_EstParameter)\n",
    "        EstConfMatrices.append(_EstConfMatrices)\n",
    "        ConfMatrix.append(_ConfMatrix)\n",
    "        \n",
    "        # waiting for all print commands to execute.\n",
    "        sleep(.5)\n",
    "        \n",
    "    return Ytrain, EstParameter, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = io.loadmat(\"/Users/devanshusingh/PycharmProjects/ML/ML2/Proj2FeatVecsSet1.mat\")['Proj2FeatVecsSet1']\n",
    "# label shape is [25000, 5] as [num_sample, num_class]\n",
    "label = io.loadmat(\"/Users/devanshusingh/PycharmProjects/ML/ML2/Proj2TargetOutputsSet1.mat\")['Proj2TargetOutputsSet1']\n",
    "data = np.concatenate((train, label), axis=1)\n",
    "np.random.shuffle(data)\n",
    "train = data[:,:-5]\n",
    "label = data[:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching Parameters for RVM:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "Ytrain, EstParameter, EstConfMatrices, ConfMatrix = MyCrossValidate(train, label, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"Ytrain\", Ytrain)\n",
    "np.save(\"EstParameter\", EstParameter)\n",
    "np.save(\"EstConfMatrices\",EstConfMatrices )\n",
    "np.save(\"ConfMatrix\", ConfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TestMyClassifier(XTest,Parameters,EstParameters):\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "        n_svc = get_svc(Parameters)\n",
    "        svc_set_para(n_svc, EstParameters)\n",
    "        Ytest = svc_probability(n_svc, XTest)\n",
    "        \n",
    "        return Ytest\n",
    "    \n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "        if len(EstParameters) == 1:\n",
    "            clf = EstParameters.get('clf')\n",
    "        else:\n",
    "            clf = EstParameters[0]\n",
    "        if np.shape(clf.classes_)[0] == 2:\n",
    "            Ytest = clf.predict_proba(XTest)\n",
    "        else:\n",
    "            Ytest = predict_proba(clf,XTest)\n",
    "            \n",
    "        return Ytest\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "        num_class = EstParameters[\"class_num\"]\n",
    "        classifier = []\n",
    "        # init all the classifiers\n",
    "        for param_dict in EstParameters[\"parameters\"]:\n",
    "            gpc_classifier = GaussianProcessClassifier(\n",
    "                kernel=Parameters[\"parameters\"][\"kernel\"],\n",
    "                optimizer=Parameters[\"parameters\"][\"optimizer\"],\n",
    "                n_restarts_optimizer=Parameters[\"parameters\"][\"n_restarts_optimizer\"],\n",
    "                max_iter_predict=Parameters[\"parameters\"][\"max_iter_predict\"],\n",
    "                warm_start=Parameters[\"parameters\"][\"warm_start\"],\n",
    "                copy_X_train=Parameters[\"parameters\"][\"copy_X_train\"],\n",
    "                random_state=Parameters[\"parameters\"][\"random_state\"],\n",
    "                multi_class=\"one_vs_rest\",\n",
    "                n_jobs=Parameters[\"parameters\"][\"n_jobs\"]\n",
    "            )\n",
    "            gpc_classifier.log_marginal_likelihood_value_ = param_dict[\"log_marginal_likelihood_value_\"]\n",
    "            gpc_classifier.classes_ = param_dict[\"classes_\"]\n",
    "            gpc_classifier.n_classes_ = param_dict[\"n_classes_\"]\n",
    "            gpc_classifier.base_estimator_ = param_dict[\"base_estimator_\"]\n",
    "            classifier.append(gpc_classifier)\n",
    "\n",
    "        # put all the classifiers into a matrix, so it is easier for calculation\n",
    "        classifier_matrix = []\n",
    "        for i in range(num_class-1):\n",
    "            classifier_matrix.append([])\n",
    "            for j in range(num_class-1):\n",
    "                classifier_matrix[i].append(None)\n",
    "\n",
    "        count = 0\n",
    "        for i in range(num_class-1):\n",
    "            for j in range(i, num_class-1):\n",
    "                classifier_matrix[i][j] = classifier[count]\n",
    "                count += 1\n",
    "\n",
    "        # calculate the output for XTest\n",
    "        out_matrix = []\n",
    "        for i in range(num_class - 1):\n",
    "            out_matrix.append([])\n",
    "            for j in range(num_class - 1):\n",
    "                out_matrix[i].append(None)\n",
    "\n",
    "        for i in range(num_class - 1):\n",
    "            for j in range(i, num_class - 1):\n",
    "                out_matrix[i][j] = classifier_matrix[i][j].predict_proba(XTest)\n",
    "\n",
    "        # calculate the whole prediction prob\n",
    "        val_shape = XTest.shape[0]\n",
    "        predict_prob_list = []\n",
    "        for i in range(num_class):\n",
    "            predict_prob_list.append(np.zeros(shape=[val_shape, 1]))\n",
    "\n",
    "        for i in range(num_class - 1):\n",
    "            for j in range(i, num_class - 1):\n",
    "                predict_prob_list[i] += out_matrix[i][j][:, 0][:, np.newaxis] / (num_class * 2)\n",
    "                predict_prob_list[j + 1] += out_matrix[i][j][:, 1][:, np.newaxis] / (num_class * 2)\n",
    "\n",
    "        result = np.concatenate(predict_prob_list, axis=1)\n",
    "\n",
    "        # calculate the probability for the one more class\n",
    "        std = np.std(result, axis=1)[:, np.newaxis]\n",
    "        other_prob = np.exp(-std) / (1 + np.exp(std * 5))\n",
    "        result = np.concatenate([result, other_prob], axis=1)\n",
    "        result = result / np.repeat((other_prob + 1), axis=1, repeats=num_class + 1)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
